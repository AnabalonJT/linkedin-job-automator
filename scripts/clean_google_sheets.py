#!/usr/bin/env python3
"""
Script para limpiar duplicados en Google Sheets.

Elimina filas duplicadas bas√°ndose en la URL del trabajo, manteniendo solo
la primera ocurrencia de cada trabajo.
"""

import sys
from pathlib import Path
from google_sheets_manager import GoogleSheetsManager
from utils import Config, Logger

def clean_duplicates():
    """Limpia trabajos duplicados del Google Sheet"""
    
    # Inicializar config y logger
    config = Config()
    logger = Logger()
    
    logger.info("üßπ Limpiando duplicados en Google Sheets...")
    
    try:
        # Inicializar Google Sheets Manager
        sheets_id = config.get_env_var('GOOGLE_SHEETS_ID')
        credentials_path = 'config/google_credentials.json'
        
        if not sheets_id:
            logger.error("‚ùå GOOGLE_SHEETS_ID no configurado en .env")
            return False
        
        if not Path(credentials_path).exists():
            logger.error(f"‚ùå Archivo de credenciales no encontrado: {credentials_path}")
            return False
        
        manager = GoogleSheetsManager(credentials_path, sheets_id)
        logger.info("‚úì Conectado a Google Sheets")
        
        # Obtener la hoja de Postulaciones usando el m√©todo correcto
        worksheet = manager.get_or_create_worksheet(
            'Postulaciones',
            headers=[
                'ID', 'Fecha Aplicaci√≥n', 'Empresa', 'Puesto', 'URL',
                'Ubicaci√≥n', 'Tipo Aplicaci√≥n', 'CV Usado', 'Estado',
                '√öltimo Update', 'Notas', 'Preguntas Pendientes'
            ]
        )
        
        # Obtener todas las filas
        sheet = worksheet.get_all_records()
        logger.info(f"üìä Total de filas: {len(sheet)}")
        
        # Identificar duplicados por URL
        seen_urls = set()
        rows_to_delete = []
        
        for idx, row in enumerate(sheet, start=2):  # Start at 2 (row 1 is header)
            url = row.get('URL', '').strip()
            if not url:
                continue
            
            if url in seen_urls:
                rows_to_delete.append(idx)
                logger.info(f"  üîç Duplicado encontrado: {row.get('T√≠tulo', 'Sin t√≠tulo')} (fila {idx})")
            else:
                seen_urls.add(url)
        
        if not rows_to_delete:
            logger.info("‚úÖ No se encontraron duplicados")
            return True
        
        logger.info(f"üóëÔ∏è  Eliminando {len(rows_to_delete)} filas duplicadas...")
        
        # Eliminar filas en orden inverso (de abajo hacia arriba)
        # para que los √≠ndices no cambien
        # Agregar delay para evitar rate limit (60 escrituras por minuto = 1 por segundo)
        for idx, row_idx in enumerate(reversed(rows_to_delete), 1):
            try:
                worksheet.delete_rows(row_idx)
                logger.info(f"  ‚úì Fila {row_idx} eliminada ({idx}/{len(rows_to_delete)})")
                
                # Delay de 1.5 segundos entre eliminaciones para evitar rate limit
                if idx < len(rows_to_delete):  # No esperar despu√©s de la √∫ltima
                    import time
                    time.sleep(1.5)
                    
            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è  Error eliminando fila {row_idx}: {e}")
                # Si es rate limit, esperar m√°s tiempo
                if '429' in str(e) or 'RATE_LIMIT' in str(e):
                    logger.warning("  ‚è∏Ô∏è  Rate limit alcanzado, esperando 60 segundos...")
                    import time
                    time.sleep(60)
                    # Reintentar
                    try:
                        worksheet.delete_rows(row_idx)
                        logger.info(f"  ‚úì Fila {row_idx} eliminada (reintento exitoso)")
                    except Exception as e2:
                        logger.error(f"  ‚úó Fallo reintento para fila {row_idx}: {e2}")
        
        logger.success(f"‚úÖ Limpieza completada. {len(rows_to_delete)} duplicados eliminados")
        logger.info(f"üìä Filas restantes: {len(sheet) - len(rows_to_delete)}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error limpiando duplicados: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = clean_duplicates()
    sys.exit(0 if success else 1)
